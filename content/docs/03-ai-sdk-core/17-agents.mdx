---
title: Agents
description: Learn about creating agents with Vercel AI SDK Core.
---

# Agents

AI agents let the language model execute several steps in a non-deterministic way.
The model can make decisions based on the context of the conversation and the user's input.

One approach to implementing agents is to allow the LLM to choose the next step in a loop.
With `generateText`, you can combine [tools](/docs/ai-sdk-core/tools-and-tool-calling) with `maxToolRoundtrips`.
This makes it possible to implement basic agents that reason at each step and make decisions based on the context.

### Example

This example demonstrates how to create an agent that solves math problems.
It has a calculator tool (using [math.js](https://mathjs.org/)) that it can call to evaluate mathematical expressions.

```ts file='main.ts'
import { openai } from '@ai-sdk/openai';
import { generateText, tool } from 'ai';
import * as mathjs from 'mathjs';
import { z } from 'zod';

const problem =
  'A taxi driver earns $9461 per 1-hour of work. ' +
  'If he works 12 hours a day and in 1 hour ' +
  'he uses 12 liters of petrol with a price  of $134 for 1 liter. ' +
  'How much money does he earn in one day?';

console.log(`PROBLEM: ${problem}`);

const { text: answer } = await generateText({
  model: openai('gpt-4-turbo'),
  system:
    'You are solving math problems. ' +
    'Reason step by step. ' +
    'Use the calculator when necessary. ' +
    'When you give the final answer, ' +
    'provide an explanation for how you arrived at it.',
  prompt: problem,
  tools: {
    calculate: tool({
      description:
        'A tool for evaluating mathematical expressions. ' +
        'Example expressions: ' +
        "'1.2 * (2 + 4.5)', '12.7 cm to inch', 'sin(45 deg) ^ 2'.",
      parameters: z.object({ expression: z.string() }),
      execute: async ({ expression }) => mathjs.evaluate(expression),
    }),
  },
  maxToolRoundtrips: 10,
});

console.log(`ANSWER: ${answer}`);
```

## Accessing information from all roundtrips

Calling `generateText` with `maxToolRoundtrips` can result in several calls to the LLM (roundtrips).
You can access information from all roundtrips by using the `roundtrips` property of the response.

```ts
const { roundtrips } = await generateText({
  model: openai('gpt-4-turbo'),
  maxToolRoundtrips: 10,
  // ...
});

// extract all tool calls from the roundtrips:
const allToolCalls = roundtrips.flatMap(roundtrip => roundtrip.toolCalls);
```
